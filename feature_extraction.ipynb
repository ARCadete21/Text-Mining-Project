{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "import math\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\ritaf\\\\Documents\\\\ESTUDOS\\\\NOVA IMS\\\\3º Ano\\\\Text Mining\\\\Projeto\\\\new_data\\\\'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "data = pd.read_csv(path + 'lyrics_fdist_lem_stem_2500.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # create a sample dataframe\n",
    "# df = pd.DataFrame({'tag': ['a', 'a', 'a', 'b', 'b', 'c', 'c', 'c', 'c']})\n",
    "\n",
    "# # calculate the distribution of the tag column\n",
    "# tag_dist = df['tag'].value_counts(normalize=True)\n",
    "\n",
    "# # calculate the number of samples to take for each tag\n",
    "# sample_sizes = np.round(tag_dist * len(df)).astype(int)\n",
    "\n",
    "# # create a list of indices for each tag\n",
    "# tag_indices = [df[df['tag'] == tag].index.tolist() for tag in tag_dist.index]\n",
    "\n",
    "# # randomly sample from each tag group\n",
    "# sample_indices = []\n",
    "# for indices, size in zip(tag_indices, sample_sizes):\n",
    "#     sample_indices += np.random.choice(indices, size, replace=False).tolist()\n",
    "\n",
    "# # extract the sample dataframe\n",
    "# sample_df = df.loc[sample_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data[['lyrics_string_fdist', 'tag']]\n",
    "df = data[['lyrics_string_fdist', 'tag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = data.sample(frac = 0.6, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics_string_fdist</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>said loved mean change mind one day pretend ca...</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kid rap hook everybody wants hurt everybody wa...</td>\n",
       "      <td>rap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>verse people tell ive changed find hard explai...</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>try get close know want chain ill leave ghost ...</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>verse see end coming ive never need way even d...</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134962</th>\n",
       "      <td>knew young many things would told chance tell ...</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134963</th>\n",
       "      <td>intro lil cash everything future chorus lil li...</td>\n",
       "      <td>rap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134964</th>\n",
       "      <td>verse born inside home three boys heart god kn...</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134965</th>\n",
       "      <td>rollin falling stars nothing wrong going strai...</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134966</th>\n",
       "      <td>verse yeah games playin games set record strai...</td>\n",
       "      <td>rap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134967 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      lyrics_string_fdist      tag\n",
       "0       said loved mean change mind one day pretend ca...     rock\n",
       "1       kid rap hook everybody wants hurt everybody wa...      rap\n",
       "2       verse people tell ive changed find hard explai...      pop\n",
       "3       try get close know want chain ill leave ghost ...      pop\n",
       "4       verse see end coming ive never need way even d...  country\n",
       "...                                                   ...      ...\n",
       "134962  knew young many things would told chance tell ...      pop\n",
       "134963  intro lil cash everything future chorus lil li...      rap\n",
       "134964  verse born inside home three boys heart god kn...     rock\n",
       "134965  rollin falling stars nothing wrong going strai...      pop\n",
       "134966  verse yeah games playin games set record strai...      rap\n",
       "\n",
       "[134967 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separating lyrics by genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lyrics = df.drop(columns=['tag'])\n",
    "pop_lyrics = df.loc[df.tag=='pop'].drop(columns=['tag'])\n",
    "rap_lyrics = df.loc[df.tag=='rap'].drop(columns=['tag'])\n",
    "rock_lyrics = df.loc[df.tag=='rock'].drop(columns=['tag'])\n",
    "rb_lyrics = df.loc[df.tag=='rb'].drop(columns=['tag'])\n",
    "country_lyrics = df.loc[df.tag=='country'].drop(columns=['tag'])\n",
    "misc_lyrics = df.loc[df.tag=='misc'].drop(columns=['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics_string_fdist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>verse people tell ive changed find hard explai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>try get close know want chain ill leave ghost ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sick got something never came around vision co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>days remember days come years none young contr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>verse never falling line caught beat little br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134957</th>\n",
       "      <td>empty room full shadows voices want find behin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134959</th>\n",
       "      <td>crazy crazy things heard say mad never really ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134961</th>\n",
       "      <td>verse beauty feels sometimes words use keeps v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134962</th>\n",
       "      <td>knew young many things would told chance tell ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134965</th>\n",
       "      <td>rollin falling stars nothing wrong going strai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55742 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      lyrics_string_fdist\n",
       "2       verse people tell ive changed find hard explai...\n",
       "3       try get close know want chain ill leave ghost ...\n",
       "6       sick got something never came around vision co...\n",
       "9       days remember days come years none young contr...\n",
       "11      verse never falling line caught beat little br...\n",
       "...                                                   ...\n",
       "134957  empty room full shadows voices want find behin...\n",
       "134959  crazy crazy things heard say mad never really ...\n",
       "134961  verse beauty feels sometimes words use keeps v...\n",
       "134962  knew young many things would told chance tell ...\n",
       "134965  rollin falling stars nothing wrong going strai...\n",
       "\n",
       "[55742 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pop_lyrics_lst = pop_lyrics['lyrics_string_fdist']\n",
    "#rap_lyrics_lst = rap_lyrics['lyrics_string_fdist']\n",
    "#rock_lyrics_lst = rock_lyrics['lyrics_string_fdist']\n",
    "#rb_lyrics_lst = rb_lyrics['lyrics_string_fdist']\n",
    "#country_lyrics_lst = country_lyrics['lyrics_string_fdist']\n",
    "#misc_lyrics_lst = misc_lyrics['lyrics_string_fdist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df #, pop_lyrics, rap_lyrics, rock_lyrics, rb_lyrics, country_lyrics, misc_lyrics\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lyrics.dropna(subset=['lyrics_string_fdist'], inplace=True)\n",
    "pop_lyrics.dropna(subset=['lyrics_string_fdist'], inplace=True)\n",
    "rap_lyrics.dropna(subset=['lyrics_string_fdist'], inplace=True)\n",
    "rock_lyrics.dropna(subset=['lyrics_string_fdist'], inplace=True)\n",
    "rb_lyrics.dropna(subset=['lyrics_string_fdist'], inplace=True)\n",
    "country_lyrics.dropna(subset=['lyrics_string_fdist'], inplace=True)\n",
    "misc_lyrics.dropna(subset=['lyrics_string_fdist'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lyrics_lyrics = ' '.join(list(all_lyrics.lyrics_string_fdist))\n",
    "all_pop_lyrics = ' '.join(list(pop_lyrics.lyrics_string_fdist))\n",
    "all_rap_lyrics = ' '.join(list(rap_lyrics.lyrics_string_fdist))\n",
    "all_rock_lyrics = ' '.join(list(rock_lyrics.lyrics_string_fdist))\n",
    "all_rb_lyrics = ' '.join(list(rb_lyrics.lyrics_string_fdist))\n",
    "all_country_lyrics = ' '.join(list(country_lyrics.lyrics_string_fdist))\n",
    "all_misc_lyrics = ' '.join(list(misc_lyrics.lyrics_string_fdist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_size = len(all_lyrics_lyrics)\n",
    "# pop_size = len(all_pop_lyrics)\n",
    "# rap_size = len(all_rap_lyrics)\n",
    "# rock_size = len(all_rock_lyrics)\n",
    "# rb_size = len(all_rb_lyrics)\n",
    "# country_size = len(all_country_lyrics)\n",
    "# misc_size = len(all_misc_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = word_tokenize(all_lyrics_lyrics)\n",
    "pop_tokens = word_tokenize(all_pop_lyrics)\n",
    "rap_tokens = word_tokenize(all_rap_lyrics)\n",
    "rock_tokens = word_tokenize(all_rock_lyrics)\n",
    "rb_tokens = word_tokenize(all_rb_lyrics)\n",
    "country_tokens = word_tokenize(all_country_lyrics)\n",
    "misc_tokens = word_tokenize(all_misc_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_all = FreqDist(all_tokens)\n",
    "freq_pop = FreqDist(pop_tokens)\n",
    "freq_rap = FreqDist(rap_tokens)\n",
    "freq_rock = FreqDist(rock_tokens)\n",
    "freq_rb = FreqDist(rb_tokens)\n",
    "freq_country = FreqDist(country_tokens)\n",
    "freq_misc = FreqDist(misc_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT NEEDED ESTÁ DENTRO DA FUNÇÃO\n",
    "# freq_all_100 = freq_all.most_common(100)\n",
    "# freq_pop_100 = freq_pop.most_common(100)\n",
    "# freq_rap_100 = freq_rap.most_common(100)\n",
    "# freq_rock_100 = freq_rock.most_common(100)\n",
    "# freq_rb_100 = freq_rb.most_common(100)\n",
    "# freq_country_100 = freq_country.most_common(100)\n",
    "# freq_misc_100 = freq_misc.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT NEEDED... ESTÁ DENTRO DA FUNÇÃO\n",
    "# total_all_words = freq_all.N()\n",
    "# total_pop_words = freq_pop.N()\n",
    "# total_rap_words = freq_rap.N()\n",
    "# total_rock_words = freq_rock.N()\n",
    "# total_rb_words = freq_rb.N()\n",
    "# total_country_words = freq_country.N()\n",
    "# total_misc_words = freq_misc.N()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESTE NÃO TEM EM CONTA O FACTO DE QUERERMOS MANTER PALAVRAS MAIS COMUNS... \n",
    "#AS PALAVRAS QUE NOS DÃO SÃO MUITO RARAS, MAS APARECEM QUASE QUE SÓ NUM ESTILO ESPECÍFICO\n",
    "\n",
    "\n",
    "# import math\n",
    "# from operator import itemgetter\n",
    "\n",
    "# def log_ratio(genre_freq, all_freq):\n",
    "#     # Calculate total number of words in genre and in all genres\n",
    "#     total_genre_words = sum(genre_freq.values())\n",
    "#     total_all_words = sum(all_freq.values())\n",
    "    \n",
    "#     # Calculate log ratios\n",
    "#     log_ratios = {word: math.log(((genre_freq[word]+1) / (total_genre_words+1)) / ((all_freq[word]+1) / (total_all_words+1))) for word in genre_freq}\n",
    "    \n",
    "#     # Sort log ratios\n",
    "#     sorted_log_ratios = sorted(log_ratios.items(), key=itemgetter(1), reverse=True)\n",
    "    \n",
    "#     return sorted_log_ratios[:20]\n",
    "\n",
    "# # Calculate top 20 words for each genre\n",
    "# top_words = {\n",
    "#     'pop': log_ratio(freq_pop, freq_all),\n",
    "#     'rap': log_ratio(freq_rap, freq_all),\n",
    "#     'rock': log_ratio(freq_rock, freq_all),\n",
    "#     'rb': log_ratio(freq_rb, freq_all),\n",
    "#     'country': log_ratio(freq_country, freq_all),\n",
    "#     'misc': log_ratio(freq_misc, freq_all)\n",
    "# }\n",
    "\n",
    "# # Print top words for each genre\n",
    "# for genre, words in top_words.items():\n",
    "#     print(f\"Top words for {genre}: {words}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words for pop: [('prechorus', 0.5588659985410767), ('tonight', 0.5131902584187034), ('love', 0.4333846845364872), ('heart', 0.4325538423951535), ('ooh', 0.38649819992147527), ('hey', 0.37315087354977694), ('away', 0.3661169679562259), ('night', 0.34488258479218525), ('alone', 0.3341675233020173), ('baby', 0.31678247651397884), ('ive', 0.3144553891752139), ('eyes', 0.31376478081464315), ('fall', 0.31354269239146837), ('light', 0.3106925974001419), ('find', 0.2968294820297687), ('believe', 0.29604439567566415), ('home', 0.2935603845537592), ('ill', 0.28835982269092236), ('world', 0.27908549748384837), ('inside', 0.26899228678984466)]\n",
      "Top words for rap: [('niggas', 0.8389884134636949), ('nigga', 0.8297372082321213), ('bitch', 0.8012863055273524), ('bitches', 0.7993400219441436), ('lil', 0.7847508112425773), ('shit', 0.743500958318561), ('ima', 0.714889561997828), ('tryna', 0.7131899992968004), ('fuck', 0.7081929985868863), ('gon', 0.7051217693447532), ('hook', 0.7044984872737532), ('ass', 0.6977272885371858), ('aint', 0.6429694462464737), ('hit', 0.5824687808044186), ('money', 0.5645715064007726), ('bout', 0.560484884288371), ('fucking', 0.5532002699946444), ('damn', 0.5506813960961064), ('pull', 0.5273978770139159), ('intro', 0.491734392975908)]\n",
      "Top words for rock: [('blood', 0.7661558987959288), ('dead', 0.6152011021884276), ('inside', 0.6009252919273419), ('prechorus', 0.5809816617226533), ('away', 0.5677597721397807), ('end', 0.5490948272168785), ('sun', 0.5460633062634245), ('fire', 0.5401145592169599), ('bridge', 0.5303989700415128), ('eyes', 0.501319821385536), ('die', 0.49638555698730513), ('alone', 0.4772915658969056), ('lost', 0.46496344335943296), ('light', 0.46400376130804455), ('fall', 0.44572787037487166), ('left', 0.44115071178242765), ('chorus', 0.43491511560080504), ('nothing', 0.4237892360098731), ('ive', 0.4237679626182387), ('pain', 0.40855977555176154)]\n",
      "Top words for rb: [('baby', 1.1542309496704688), ('girl', 1.0410348908212421), ('ooh', 1.0176007992466247), ('love', 0.7538960246662376), ('prechorus', 0.6821434720010412), ('yeah', 0.6409818894178297), ('youre', 0.5523052016775181), ('hey', 0.5414492677801181), ('bridge', 0.5329169480756543), ('outro', 0.4997017214631868), ('body', 0.49262937645793337), ('need', 0.4837955918341121), ('cant', 0.4804576212687161), ('dont', 0.44917119547717305), ('know', 0.42407149736822564), ('chorus', 0.41762283585793303), ('tonight', 0.4117148989332611), ('want', 0.4060427848817215), ('tell', 0.3952943555335521), ('mine', 0.38448957262402295)]\n",
      "Top words for country: [('country', 1.8373297726026672), ('town', 1.2913811815243128), ('old', 1.1428663701089956), ('road', 1.1202043892634455), ('song', 1.0893713378686538), ('blue', 0.8847615255512349), ('little', 0.8378105119213014), ('home', 0.8226892937916953), ('lord', 0.8119302272644925), ('well', 0.8041435742423771), ('long', 0.6895750035084756), ('chorus', 0.627970778579041), ('heart', 0.5456387291420904), ('good', 0.5009162794471163), ('verse', 0.49556951983067615), ('tonight', 0.4761069149383712), ('night', 0.45368196448183346), ('ive', 0.45290585315924226), ('gone', 0.44926361137246773), ('bridge', 0.42453987579638386)]\n",
      "Top words for misc: [('thou', 2.2138461516287133), ('also', 2.1136802326732536), ('sir', 2.105854699466473), ('thy', 2.048598769216588), ('upon', 1.8071787643371744), ('men', 1.6318000988568386), ('great', 1.5594944468575749), ('may', 1.5480999531766555), ('father', 1.4912052001057383), ('yet', 1.379400209337085), ('must', 1.2645318293368364), ('first', 1.1339911424436455), ('went', 1.1081491427864434), ('house', 1.0764024676800845), ('three', 1.0610507085653615), ('years', 1.0110972911849239), ('said', 1.009840908508844), ('part', 0.9791894751124748), ('saw', 0.94568366863824), ('many', 0.9198963999110997)]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from operator import itemgetter\n",
    "\n",
    "def log_ratio(genre_freq, all_freq):\n",
    "    # Calculate total number of words in genre and in all genres\n",
    "    total_genre_words = genre_freq.N()\n",
    "    total_all_words = all_freq.N()\n",
    "\n",
    "    # Calculate the genre's 100 top words\n",
    "    genre_freq_100 = genre_freq.most_common(100)\n",
    "    \n",
    "    # Calculate log ratios for the 100 top words\n",
    "    log_ratios = {word: math.log(((freq + 1) / (total_genre_words + 1)) / ((all_freq[word] + 1) / (total_all_words + 1))) for word, freq in genre_freq_100}\n",
    "    \n",
    "    # Sort log ratios\n",
    "    sorted_log_ratios = sorted(log_ratios.items(), key=itemgetter(1), reverse=True)\n",
    "    \n",
    "    return sorted_log_ratios[:20]\n",
    "\n",
    "# Calculate top 20 words for each genre\n",
    "top_words = {\n",
    "    'pop': log_ratio(freq_pop, freq_all),\n",
    "    'rap': log_ratio(freq_rap, freq_all),\n",
    "    'rock': log_ratio(freq_rock, freq_all),\n",
    "    'rb': log_ratio(freq_rb, freq_all),\n",
    "    'country': log_ratio(freq_country, freq_all),\n",
    "    'misc': log_ratio(freq_misc, freq_all)\n",
    "}\n",
    "\n",
    "# Print top words for each genre\n",
    "for genre, words in top_words.items():\n",
    "    print(f\"Top words for {genre}: {words}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3543102\n",
      "8410303\n"
     ]
    }
   ],
   "source": [
    "total_rap_words = sum(freq_rap.values())\n",
    "total_all_words = sum(freq_all.values())\n",
    "print(total_rap_words)\n",
    "print(total_all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35505\n",
      "37994\n"
     ]
    }
   ],
   "source": [
    "nigga_rap = freq_rap['nigga']\n",
    "nigga_all = freq_all['nigga']\n",
    "print(nigga_rap)\n",
    "print(nigga_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010020880008534894\n",
      "0.004517554242694942\n"
     ]
    }
   ],
   "source": [
    "perc_rap = nigga_rap/total_rap_words\n",
    "perc_all = nigga_all/total_all_words\n",
    "print(perc_rap)\n",
    "print(perc_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005463623192616725"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.log((perc_rap+1)/(perc_all+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words_all = freq_all.N()\n",
    "total_words_pop = freq_pop.N()\n",
    "total_words_rap = freq_rap.N()\n",
    "total_words_rock = freq_rock.N()\n",
    "total_words_rb = freq_rb.N()\n",
    "total_words_country = freq_country.N()\n",
    "total_words_misc = freq_misc.N()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_all = FreqDist({word: count / total_words_all * 100 for word, count in freq_all.items()})\n",
    "percentage_pop = FreqDist({word: count / total_words_pop * 100 for word, count in freq_pop.items()})\n",
    "percentage_rap = FreqDist({word: count / total_words_rap * 100 for word, count in freq_rap.items()})\n",
    "percentage_rock = FreqDist({word: count / total_words_rock * 100 for word, count in freq_rock.items()})\n",
    "percentage_rb = FreqDist({word: count / total_words_rb * 100 for word, count in freq_rb.items()})\n",
    "percentage_country = FreqDist({word: count / total_words_country * 100 for word, count in freq_country.items()})\n",
    "percentage_misc = FreqDist({word: count / total_words_misc * 100 for word, count in freq_misc.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'like': 2.939751397779604, 'dont': 2.475035679451739, 'know': 2.2888473815984987, 'got': 1.855343380613041, 'get': 1.7164661011618725, 'love': 1.3948605656657078, 'never': 1.1713489989599661, 'cant': 1.1225398181254587, 'aint': 1.0971899585544065, 'see': 1.0814354726577629, ...})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dont', 2.590864189387622),\n",
       " ('know', 2.4946328761658867),\n",
       " ('like', 2.257254451139935),\n",
       " ('love', 2.0948665639571136),\n",
       " ('got', 1.4974157710990394),\n",
       " ('get', 1.4084872013531278),\n",
       " ('never', 1.398828734175426),\n",
       " ('cant', 1.3178311008925052),\n",
       " ('want', 1.2958050842799416),\n",
       " ('youre', 1.2871674307063874),\n",
       " ('see', 1.1828481327748699),\n",
       " ('one', 1.1636882466662584),\n",
       " ('make', 1.049985315988925),\n",
       " ('feel', 1.0485326197061),\n",
       " ('time', 1.019321645802807),\n",
       " ('let', 0.9664749107573337),\n",
       " ('come', 0.9108798313930022),\n",
       " ('need', 0.8976092545390869),\n",
       " ('take', 0.866867060229573),\n",
       " ('say', 0.8459011192828549)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_pop.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('like', 2.939751397779604),\n",
       " ('dont', 2.475035679451739),\n",
       " ('know', 2.2888473815984987),\n",
       " ('got', 1.855343380613041),\n",
       " ('get', 1.7164661011618725),\n",
       " ('love', 1.3948605656657078),\n",
       " ('never', 1.1713489989599661),\n",
       " ('cant', 1.1225398181254587),\n",
       " ('aint', 1.0971899585544065),\n",
       " ('see', 1.0814354726577629),\n",
       " ('one', 1.0752169095453517),\n",
       " ('want', 1.0655977555148726),\n",
       " ('make', 0.97865677372147),\n",
       " ('time', 0.914925419452783),\n",
       " ('back', 0.8513843080326594),\n",
       " ('youre', 0.840920951361681),\n",
       " ('need', 0.8025632370201168),\n",
       " ('feel', 0.7852986985130024),\n",
       " ('say', 0.7718152366210825),\n",
       " ('take', 0.7678320269792897)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_all.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.475035679451739"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_all['dont']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0457366720574244"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.log(percentage_pop['dont']/percentage_all['dont'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4066954013738429"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.log(percentage_pop['love']/percentage_all['love'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume you have FreqDist objects for each genre and overall\n",
    "# For example, freq_dist_genre1, freq_dist_genre2, ..., freq_dist_overall\n",
    "\n",
    "def calculate_log_ratios(freq_dist_genre, freq_dist_overall, top_n=20):\n",
    "    log_ratios = {}\n",
    "\n",
    "    # Calculate log likelihood ratios for each word\n",
    "    for word in set(freq_dist_genre + freq_dist_overall):\n",
    "        # Probability of the word occurring in the given genre\n",
    "        p_word_genre = (freq_dist_genre[word] + 1) / (sum(freq_dist_genre.values()) + len(freq_dist_genre))\n",
    "\n",
    "        # Probability of the word occurring overall\n",
    "        p_word_overall = (freq_dist_overall[word] + 1) / (sum(freq_dist_overall.values()) + len(freq_dist_overall))\n",
    "\n",
    "        # Log likelihood ratio\n",
    "        log_ratio = math.log(p_word_genre / p_word_overall)\n",
    "\n",
    "        # Store the log ratio for the word\n",
    "        log_ratios[word] = log_ratio\n",
    "\n",
    "    # Get the top N words based on log ratios\n",
    "    top_words = sorted(log_ratios, key=log_ratios.get, reverse=True)[:top_n]\n",
    "\n",
    "    return top_words\n",
    "\n",
    "# Example usage\n",
    "genre1_top_words = calculate_log_ratios(percentage_pop, percentage_all)\n",
    "genre2_top_words = calculate_log_ratios(freq_dist_genre2, freq_dist_overall)\n",
    "# Repeat for other genres\n",
    "\n",
    "# Print or use top words for each genre\n",
    "print(\"Top words for Genre 1:\", genre1_top_words)\n",
    "print(\"Top words for Genre 2:\", genre2_top_words)\n",
    "# Repeat for other genres\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NovaIMS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
