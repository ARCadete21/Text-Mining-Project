{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "import math\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\ritaf\\\\Documents\\\\ESTUDOS\\\\NOVA IMS\\\\3ยบ Ano\\\\Text Mining\\\\Projeto\\\\new_data\\\\'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "data = pd.read_csv(path + 'text_train_btp_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # create a sample dataframe\n",
    "# df = pd.DataFrame({'tag': ['a', 'a', 'a', 'b', 'b', 'c', 'c', 'c', 'c']})\n",
    "\n",
    "# # calculate the distribution of the tag column\n",
    "# tag_dist = df['tag'].value_counts(normalize=True)\n",
    "\n",
    "# # calculate the number of samples to take for each tag\n",
    "# sample_sizes = np.round(tag_dist * len(df)).astype(int)\n",
    "\n",
    "# # create a list of indices for each tag\n",
    "# tag_indices = [df[df['tag'] == tag].index.tolist() for tag in tag_dist.index]\n",
    "\n",
    "# # randomly sample from each tag group\n",
    "# sample_indices = []\n",
    "# for indices, size in zip(tag_indices, sample_sizes):\n",
    "#     sample_indices += np.random.choice(indices, size, replace=False).tolist()\n",
    "\n",
    "# # extract the sample dataframe\n",
    "# sample_df = df.loc[sample_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data[['lyrics_string_fdist', 'tag']]\n",
    "df = data[['lyrics_string_fdist', 'tag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = data.sample(frac = 0.6, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics_string_fdist</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>said loved mean change mind one walk walk like...</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wants wants cry face put time make wants wants...</td>\n",
       "      <td>rap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>verse tell ive find hard feel make better say ...</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>youve try get know want leave took second your...</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>verse see end coming ive never need way even a...</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134962</th>\n",
       "      <td>knew young many things told didnt chance tell ...</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134963</th>\n",
       "      <td>intro lil lil lil god god cut kill kill two bi...</td>\n",
       "      <td>rap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134964</th>\n",
       "      <td>verse born inside god knows made broke back ke...</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134965</th>\n",
       "      <td>falling stars nothing going straight think fin...</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134966</th>\n",
       "      <td>verse aint set game dont listen always one wan...</td>\n",
       "      <td>rap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134967 rows ร 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      lyrics_string_fdist      tag\n",
       "0       said loved mean change mind one walk walk like...     rock\n",
       "1       wants wants cry face put time make wants wants...      rap\n",
       "2       verse tell ive find hard feel make better say ...      pop\n",
       "3       youve try get know want leave took second your...      pop\n",
       "4       verse see end coming ive never need way even a...  country\n",
       "...                                                   ...      ...\n",
       "134962  knew young many things told didnt chance tell ...      pop\n",
       "134963  intro lil lil lil god god cut kill kill two bi...      rap\n",
       "134964  verse born inside god knows made broke back ke...     rock\n",
       "134965  falling stars nothing going straight think fin...      pop\n",
       "134966  verse aint set game dont listen always one wan...      rap\n",
       "\n",
       "[134967 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separating lyrics by genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lyrics = df.drop(columns=['tag'])\n",
    "pop_lyrics = df.loc[df.tag=='pop'].drop(columns=['tag'])\n",
    "rap_lyrics = df.loc[df.tag=='rap'].drop(columns=['tag'])\n",
    "rock_lyrics = df.loc[df.tag=='rock'].drop(columns=['tag'])\n",
    "rb_lyrics = df.loc[df.tag=='rb'].drop(columns=['tag'])\n",
    "country_lyrics = df.loc[df.tag=='country'].drop(columns=['tag'])\n",
    "misc_lyrics = df.loc[df.tag=='misc'].drop(columns=['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pop_lyrics_lst = pop_lyrics['lyrics_string_fdist']\n",
    "#rap_lyrics_lst = rap_lyrics['lyrics_string_fdist']\n",
    "#rock_lyrics_lst = rock_lyrics['lyrics_string_fdist']\n",
    "#rb_lyrics_lst = rb_lyrics['lyrics_string_fdist']\n",
    "#country_lyrics_lst = country_lyrics['lyrics_string_fdist']\n",
    "#misc_lyrics_lst = misc_lyrics['lyrics_string_fdist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df #, pop_lyrics, rap_lyrics, rock_lyrics, rb_lyrics, country_lyrics, misc_lyrics\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lyrics.dropna(subset=['lyrics_string_fdist'], inplace=True)\n",
    "pop_lyrics.dropna(subset=['lyrics_string_fdist'], inplace=True)\n",
    "rap_lyrics.dropna(subset=['lyrics_string_fdist'], inplace=True)\n",
    "rock_lyrics.dropna(subset=['lyrics_string_fdist'], inplace=True)\n",
    "rb_lyrics.dropna(subset=['lyrics_string_fdist'], inplace=True)\n",
    "country_lyrics.dropna(subset=['lyrics_string_fdist'], inplace=True)\n",
    "misc_lyrics.dropna(subset=['lyrics_string_fdist'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lyrics_lyrics = ' '.join(list(all_lyrics.lyrics_string_fdist))\n",
    "all_pop_lyrics = ' '.join(list(pop_lyrics.lyrics_string_fdist))\n",
    "all_rap_lyrics = ' '.join(list(rap_lyrics.lyrics_string_fdist))\n",
    "all_rock_lyrics = ' '.join(list(rock_lyrics.lyrics_string_fdist))\n",
    "all_rb_lyrics = ' '.join(list(rb_lyrics.lyrics_string_fdist))\n",
    "all_country_lyrics = ' '.join(list(country_lyrics.lyrics_string_fdist))\n",
    "all_misc_lyrics = ' '.join(list(misc_lyrics.lyrics_string_fdist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_size = len(all_lyrics_lyrics)\n",
    "# pop_size = len(all_pop_lyrics)\n",
    "# rap_size = len(all_rap_lyrics)\n",
    "# rock_size = len(all_rock_lyrics)\n",
    "# rb_size = len(all_rb_lyrics)\n",
    "# country_size = len(all_country_lyrics)\n",
    "# misc_size = len(all_misc_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = word_tokenize(all_lyrics_lyrics)\n",
    "pop_tokens = word_tokenize(all_pop_lyrics)\n",
    "rap_tokens = word_tokenize(all_rap_lyrics)\n",
    "rock_tokens = word_tokenize(all_rock_lyrics)\n",
    "rb_tokens = word_tokenize(all_rb_lyrics)\n",
    "country_tokens = word_tokenize(all_country_lyrics)\n",
    "misc_tokens = word_tokenize(all_misc_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_all = FreqDist(all_tokens)\n",
    "freq_pop = FreqDist(pop_tokens)\n",
    "freq_rap = FreqDist(rap_tokens)\n",
    "freq_rock = FreqDist(rock_tokens)\n",
    "freq_rb = FreqDist(rb_tokens)\n",
    "freq_country = FreqDist(country_tokens)\n",
    "freq_misc = FreqDist(misc_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words_all = freq_all.N()\n",
    "total_words_pop = freq_pop.N()\n",
    "total_words_rap = freq_rap.N()\n",
    "total_words_rock = freq_rock.N()\n",
    "total_words_rb = freq_rb.N()\n",
    "total_words_country = freq_country.N()\n",
    "total_words_misc = freq_misc.N()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_all = FreqDist({word: count / total_words_all * 100 for word, count in freq_all.items()})\n",
    "percentage_pop = FreqDist({word: count / total_words_pop * 100 for word, count in freq_pop.items()})\n",
    "percentage_rap = FreqDist({word: count / total_words_rap * 100 for word, count in freq_rap.items()})\n",
    "percentage_rock = FreqDist({word: count / total_words_rock * 100 for word, count in freq_rock.items()})\n",
    "percentage_rb = FreqDist({word: count / total_words_rb * 100 for word, count in freq_rb.items()})\n",
    "percentage_country = FreqDist({word: count / total_words_country * 100 for word, count in freq_country.items()})\n",
    "percentage_misc = FreqDist({word: count / total_words_misc * 100 for word, count in freq_misc.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'like': 2.939751397779604, 'dont': 2.475035679451739, 'know': 2.2888473815984987, 'got': 1.855343380613041, 'get': 1.7164661011618725, 'love': 1.3948605656657078, 'never': 1.1713489989599661, 'cant': 1.1225398181254587, 'aint': 1.0971899585544065, 'see': 1.0814354726577629, ...})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dont', 2.590864189387622),\n",
       " ('know', 2.4946328761658867),\n",
       " ('like', 2.257254451139935),\n",
       " ('love', 2.0948665639571136),\n",
       " ('got', 1.4974157710990394),\n",
       " ('get', 1.4084872013531278),\n",
       " ('never', 1.398828734175426),\n",
       " ('cant', 1.3178311008925052),\n",
       " ('want', 1.2958050842799416),\n",
       " ('youre', 1.2871674307063874),\n",
       " ('see', 1.1828481327748699),\n",
       " ('one', 1.1636882466662584),\n",
       " ('make', 1.049985315988925),\n",
       " ('feel', 1.0485326197061),\n",
       " ('time', 1.019321645802807),\n",
       " ('let', 0.9664749107573337),\n",
       " ('come', 0.9108798313930022),\n",
       " ('need', 0.8976092545390869),\n",
       " ('take', 0.866867060229573),\n",
       " ('say', 0.8459011192828549)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_pop.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('like', 2.939751397779604),\n",
       " ('dont', 2.475035679451739),\n",
       " ('know', 2.2888473815984987),\n",
       " ('got', 1.855343380613041),\n",
       " ('get', 1.7164661011618725),\n",
       " ('love', 1.3948605656657078),\n",
       " ('never', 1.1713489989599661),\n",
       " ('cant', 1.1225398181254587),\n",
       " ('aint', 1.0971899585544065),\n",
       " ('see', 1.0814354726577629),\n",
       " ('one', 1.0752169095453517),\n",
       " ('want', 1.0655977555148726),\n",
       " ('make', 0.97865677372147),\n",
       " ('time', 0.914925419452783),\n",
       " ('back', 0.8513843080326594),\n",
       " ('youre', 0.840920951361681),\n",
       " ('need', 0.8025632370201168),\n",
       " ('feel', 0.7852986985130024),\n",
       " ('say', 0.7718152366210825),\n",
       " ('take', 0.7678320269792897)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_all.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.475035679451739"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_all['dont']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0457366720574244"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.log(percentage_pop['dont']/percentage_all['dont'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4066954013738429"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.log(percentage_pop['love']/percentage_all['love'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume you have FreqDist objects for each genre and overall\n",
    "# For example, freq_dist_genre1, freq_dist_genre2, ..., freq_dist_overall\n",
    "\n",
    "def calculate_log_ratios(freq_dist_genre, freq_dist_overall, top_n=20):\n",
    "    log_ratios = {}\n",
    "\n",
    "    # Calculate log likelihood ratios for each word\n",
    "    for word in set(freq_dist_genre + freq_dist_overall):\n",
    "        # Probability of the word occurring in the given genre\n",
    "        p_word_genre = (freq_dist_genre[word] + 1) / (sum(freq_dist_genre.values()) + len(freq_dist_genre))\n",
    "\n",
    "        # Probability of the word occurring overall\n",
    "        p_word_overall = (freq_dist_overall[word] + 1) / (sum(freq_dist_overall.values()) + len(freq_dist_overall))\n",
    "\n",
    "        # Log likelihood ratio\n",
    "        log_ratio = math.log(p_word_genre / p_word_overall)\n",
    "\n",
    "        # Store the log ratio for the word\n",
    "        log_ratios[word] = log_ratio\n",
    "\n",
    "    # Get the top N words based on log ratios\n",
    "    top_words = sorted(log_ratios, key=log_ratios.get, reverse=True)[:top_n]\n",
    "\n",
    "    return top_words\n",
    "\n",
    "# Example usage\n",
    "genre1_top_words = calculate_log_ratios(percentage_pop, percentage_all)\n",
    "genre2_top_words = calculate_log_ratios(freq_dist_genre2, freq_dist_overall)\n",
    "# Repeat for other genres\n",
    "\n",
    "# Print or use top words for each genre\n",
    "print(\"Top words for Genre 1:\", genre1_top_words)\n",
    "print(\"Top words for Genre 2:\", genre2_top_words)\n",
    "# Repeat for other genres\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NovaIMS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
