{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 15, 5\n",
    "\n",
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk import pos_tag\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import math\n",
    "from operator import itemgetter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from utils import *\n",
    "from path import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(path + 'data_updated\\\\train.csv', index_col=-1)\n",
    "test_data = pd.read_csv(path + 'data_updated\\\\test.csv', index_col=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "      <th>artist</th>\n",
       "      <th>year</th>\n",
       "      <th>views</th>\n",
       "      <th>features</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>535805</th>\n",
       "      <td>Walk Away</td>\n",
       "      <td>rock</td>\n",
       "      <td>Tony Molina</td>\n",
       "      <td>2013</td>\n",
       "      <td>699</td>\n",
       "      <td>{}</td>\n",
       "      <td>When you said you loved me\\nDid you mean it th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7519483</th>\n",
       "      <td>Gotta Make It Kid Naruto Rap</td>\n",
       "      <td>rap</td>\n",
       "      <td>Reece Lett</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>{Sl!ck}</td>\n",
       "      <td>Kid Naruto Rap\\n[Hook]\\nEverybody wants you to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4892808</th>\n",
       "      <td>​this is what i asked for</td>\n",
       "      <td>pop</td>\n",
       "      <td>Elliot (DNK)</td>\n",
       "      <td>2019</td>\n",
       "      <td>389</td>\n",
       "      <td>{}</td>\n",
       "      <td>[Verse 1]\\nPeople tell me I've changed\\nI find...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584150</th>\n",
       "      <td>Stealing Hearts</td>\n",
       "      <td>pop</td>\n",
       "      <td>Katie Armiger</td>\n",
       "      <td>2013</td>\n",
       "      <td>126</td>\n",
       "      <td>{}</td>\n",
       "      <td>You've been warned about me\\nDon't try to get ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7639050</th>\n",
       "      <td>Get Ready</td>\n",
       "      <td>country</td>\n",
       "      <td>John Campbell Munro</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>{}</td>\n",
       "      <td>[Verse 1]\\nI can see the end is coming but I’v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702980</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>pop</td>\n",
       "      <td>Tijuana Sweetheart</td>\n",
       "      <td>2007</td>\n",
       "      <td>48</td>\n",
       "      <td>{}</td>\n",
       "      <td>If I knew when I was young that I'd be older\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4802970</th>\n",
       "      <td>Belly Shit</td>\n",
       "      <td>rap</td>\n",
       "      <td>Lil Gotit</td>\n",
       "      <td>2019</td>\n",
       "      <td>3593</td>\n",
       "      <td>{\"Lil Troup\"}</td>\n",
       "      <td>[Intro: Lil Gotit]\\nCash\\nWah-wah-wah\\nWah-wah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403929</th>\n",
       "      <td>The Four Loves</td>\n",
       "      <td>rock</td>\n",
       "      <td>Heath McNease</td>\n",
       "      <td>2014</td>\n",
       "      <td>301</td>\n",
       "      <td>{}</td>\n",
       "      <td>[Verse 1]\\nI was born inside a home\\nThe young...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000723</th>\n",
       "      <td>Ball And Chain</td>\n",
       "      <td>pop</td>\n",
       "      <td>Transmatic</td>\n",
       "      <td>2001</td>\n",
       "      <td>46</td>\n",
       "      <td>{}</td>\n",
       "      <td>Rollin' by the pool the falling stars are not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6177674</th>\n",
       "      <td>It Aint Epic Enough</td>\n",
       "      <td>rap</td>\n",
       "      <td>TheGodlyRiskTakers</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>{}</td>\n",
       "      <td>[Verse 1: GodlyRiskTaker A]\\nYeah Epic Games, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134967 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                title      tag               artist  year  \\\n",
       "id                                                                          \n",
       "535805                      Walk Away     rock          Tony Molina  2013   \n",
       "7519483  Gotta Make It Kid Naruto Rap      rap           Reece Lett  2021   \n",
       "4892808     ​this is what i asked for      pop         Elliot (DNK)  2019   \n",
       "1584150               Stealing Hearts      pop        Katie Armiger  2013   \n",
       "7639050                     Get Ready  country  John Campbell Munro     1   \n",
       "...                               ...      ...                  ...   ...   \n",
       "1702980                     Manhattan      pop   Tijuana Sweetheart  2007   \n",
       "4802970                    Belly Shit      rap            Lil Gotit  2019   \n",
       "403929                 The Four Loves     rock        Heath McNease  2014   \n",
       "1000723                Ball And Chain      pop           Transmatic  2001   \n",
       "6177674           It Aint Epic Enough      rap   TheGodlyRiskTakers  2020   \n",
       "\n",
       "         views       features  \\\n",
       "id                              \n",
       "535805     699             {}   \n",
       "7519483      4        {Sl!ck}   \n",
       "4892808    389             {}   \n",
       "1584150    126             {}   \n",
       "7639050      2             {}   \n",
       "...        ...            ...   \n",
       "1702980     48             {}   \n",
       "4802970   3593  {\"Lil Troup\"}   \n",
       "403929     301             {}   \n",
       "1000723     46             {}   \n",
       "6177674      6             {}   \n",
       "\n",
       "                                                    lyrics  \n",
       "id                                                          \n",
       "535805   When you said you loved me\\nDid you mean it th...  \n",
       "7519483  Kid Naruto Rap\\n[Hook]\\nEverybody wants you to...  \n",
       "4892808  [Verse 1]\\nPeople tell me I've changed\\nI find...  \n",
       "1584150  You've been warned about me\\nDon't try to get ...  \n",
       "7639050  [Verse 1]\\nI can see the end is coming but I’v...  \n",
       "...                                                    ...  \n",
       "1702980  If I knew when I was young that I'd be older\\n...  \n",
       "4802970  [Intro: Lil Gotit]\\nCash\\nWah-wah-wah\\nWah-wah...  \n",
       "403929   [Verse 1]\\nI was born inside a home\\nThe young...  \n",
       "1000723  Rollin' by the pool the falling stars are not ...  \n",
       "6177674  [Verse 1: GodlyRiskTaker A]\\nYeah Epic Games, ...  \n",
       "\n",
       "[134967 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive sentiments - 1\n",
    "# Negative sentiments - 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "535805     When you said you loved me\\nDid you mean it th...\n",
       "7519483    Kid Naruto Rap\\n[Hook]\\nEverybody wants you to...\n",
       "4892808    [Verse 1]\\nPeople tell me I've changed\\nI find...\n",
       "1584150    You've been warned about me\\nDon't try to get ...\n",
       "7639050    [Verse 1]\\nI can see the end is coming but I’v...\n",
       "                                 ...                        \n",
       "1702980    If I knew when I was young that I'd be older\\n...\n",
       "4802970    [Intro: Lil Gotit]\\nCash\\nWah-wah-wah\\nWah-wah...\n",
       "403929     [Verse 1]\\nI was born inside a home\\nThe young...\n",
       "1000723    Rollin' by the pool the falling stars are not ...\n",
       "6177674    [Verse 1: GodlyRiskTaker A]\\nYeah Epic Games, ...\n",
       "Name: lyrics, Length: 134967, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics = train['lyrics'].copy()\n",
    "lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "      <th>artist</th>\n",
       "      <th>year</th>\n",
       "      <th>views</th>\n",
       "      <th>features</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [title, tag, artist, year, views, features, lyrics]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing values\n",
    "train[train['lyrics'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "      <th>artist</th>\n",
       "      <th>year</th>\n",
       "      <th>views</th>\n",
       "      <th>features</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1728585</th>\n",
       "      <td>Always</td>\n",
       "      <td>pop</td>\n",
       "      <td>Plumb</td>\n",
       "      <td>2007</td>\n",
       "      <td>336</td>\n",
       "      <td>{}</td>\n",
       "      <td>Out of nowhere\\nYou came\\nFrom a little dust\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2205183</th>\n",
       "      <td>Paper Cup Words</td>\n",
       "      <td>pop</td>\n",
       "      <td>Elin Ruth</td>\n",
       "      <td>2015</td>\n",
       "      <td>62</td>\n",
       "      <td>{}</td>\n",
       "      <td>I'll let it burn\\nWords in a dirty paper cup\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3651429</th>\n",
       "      <td>On The Sunny Side Of The Street Duet</td>\n",
       "      <td>pop</td>\n",
       "      <td>Tony Bennett</td>\n",
       "      <td>2011</td>\n",
       "      <td>289</td>\n",
       "      <td>{\"Willie Nelson\"}</td>\n",
       "      <td>Grab your coat, grab your hat\\nLeave your worr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171570</th>\n",
       "      <td>Fascist Smash Punch Out mix</td>\n",
       "      <td>pop</td>\n",
       "      <td>Kill Switch...Klick</td>\n",
       "      <td>2015</td>\n",
       "      <td>57</td>\n",
       "      <td>{}</td>\n",
       "      <td>Learn to hate for hatreds sake\\nLearn to kill ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822768</th>\n",
       "      <td>Honeysuckle Rose</td>\n",
       "      <td>pop</td>\n",
       "      <td>Fats Waller and His Rhythm</td>\n",
       "      <td>2015</td>\n",
       "      <td>130</td>\n",
       "      <td>{}</td>\n",
       "      <td>Every honey bee fills with jealousy\\nWhen they...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1843064</th>\n",
       "      <td>In My Arms Bimbo Jones extended mix</td>\n",
       "      <td>pop</td>\n",
       "      <td>Plumb</td>\n",
       "      <td>2015</td>\n",
       "      <td>201</td>\n",
       "      <td>{}</td>\n",
       "      <td>Your baby blues\\nSo full of wonder\\nYour curly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2339574</th>\n",
       "      <td>Macklemore and Ryan Lewis’s “Wing$” 2</td>\n",
       "      <td>rap</td>\n",
       "      <td>TeachSkogs</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>{}</td>\n",
       "      <td>[Verse 1]\\nI was seven years old\\nWhen I got m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859758</th>\n",
       "      <td>Jubilation This Thing Called Life K.C.s Camp P...</td>\n",
       "      <td>pop</td>\n",
       "      <td>Anything Box</td>\n",
       "      <td>2015</td>\n",
       "      <td>19</td>\n",
       "      <td>{}</td>\n",
       "      <td>Every time I close my eyes\\nI hide behind the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573430</th>\n",
       "      <td>Awake And Nervous Radio Sessions</td>\n",
       "      <td>pop</td>\n",
       "      <td>IQ (EN)</td>\n",
       "      <td>1993</td>\n",
       "      <td>26</td>\n",
       "      <td>{}</td>\n",
       "      <td>So the certanty is I can get no air\\nGetting n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237935</th>\n",
       "      <td>Take a Picture Club 69 trance dub</td>\n",
       "      <td>pop</td>\n",
       "      <td>Filter</td>\n",
       "      <td>2015</td>\n",
       "      <td>17</td>\n",
       "      <td>{}</td>\n",
       "      <td>Awake on my airplane\\nAwake on my airplane\\nMy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     title  tag  \\\n",
       "id                                                                \n",
       "1728585                                             Always  pop   \n",
       "2205183                                    Paper Cup Words  pop   \n",
       "3651429               On The Sunny Side Of The Street Duet  pop   \n",
       "1171570                        Fascist Smash Punch Out mix  pop   \n",
       "822768                                    Honeysuckle Rose  pop   \n",
       "...                                                    ...  ...   \n",
       "1843064                In My Arms Bimbo Jones extended mix  pop   \n",
       "2339574              Macklemore and Ryan Lewis’s “Wing$” 2  rap   \n",
       "859758   Jubilation This Thing Called Life K.C.s Camp P...  pop   \n",
       "1573430                   Awake And Nervous Radio Sessions  pop   \n",
       "1237935                  Take a Picture Club 69 trance dub  pop   \n",
       "\n",
       "                             artist  year  views           features  \\\n",
       "id                                                                    \n",
       "1728585                       Plumb  2007    336                 {}   \n",
       "2205183                   Elin Ruth  2015     62                 {}   \n",
       "3651429                Tony Bennett  2011    289  {\"Willie Nelson\"}   \n",
       "1171570         Kill Switch...Klick  2015     57                 {}   \n",
       "822768   Fats Waller and His Rhythm  2015    130                 {}   \n",
       "...                             ...   ...    ...                ...   \n",
       "1843064                       Plumb  2015    201                 {}   \n",
       "2339574                  TeachSkogs  2015      7                 {}   \n",
       "859758                 Anything Box  2015     19                 {}   \n",
       "1573430                     IQ (EN)  1993     26                 {}   \n",
       "1237935                      Filter  2015     17                 {}   \n",
       "\n",
       "                                                    lyrics  \n",
       "id                                                          \n",
       "1728585  Out of nowhere\\nYou came\\nFrom a little dust\\n...  \n",
       "2205183  I'll let it burn\\nWords in a dirty paper cup\\n...  \n",
       "3651429  Grab your coat, grab your hat\\nLeave your worr...  \n",
       "1171570  Learn to hate for hatreds sake\\nLearn to kill ...  \n",
       "822768   Every honey bee fills with jealousy\\nWhen they...  \n",
       "...                                                    ...  \n",
       "1843064  Your baby blues\\nSo full of wonder\\nYour curly...  \n",
       "2339574  [Verse 1]\\nI was seven years old\\nWhen I got m...  \n",
       "859758   Every time I close my eyes\\nI hide behind the ...  \n",
       "1573430  So the certanty is I can get no air\\nGetting n...  \n",
       "1237935  Awake on my airplane\\nAwake on my airplane\\nMy...  \n",
       "\n",
       "[178 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# já feito no \"project\"\n",
    "\n",
    "# duplicates\n",
    "train[train['lyrics'].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# já feito no \"project\"\n",
    "\n",
    "display(train[train.duplicated(['year', 'lyrics'])]) #85\n",
    "display(train[train.duplicated(['views', 'lyrics'])]) #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same year, \n",
    "# same title, \n",
    "# same lyrics\n",
    "# different artist\n",
    "\n",
    "train[train['title'] == \"Honeysuckle Rose\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train[train.duplicated(['title', 'artist', 'features', 'lyrics'])] #0\n",
    "# train[train.duplicated(['title', 'artist', 'lyrics'])] #0\n",
    "display(train[train.duplicated(['title', 'lyrics'])]) #24 --- covers\n",
    "display(train[train.duplicated(['artist', 'lyrics'])]) #111 --- labeled versions (\"acoustic\", \"remix\", \"extended\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strange Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['year'] < 1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text cleaning\n",
    "    # Handle Email adresses\n",
    "    # Remove HTML tags\n",
    "    # Word normalization\n",
    "    # split into sentences\n",
    "\n",
    "# Feature Extraction - Encode Text into Numbers\n",
    "    # Vectorization\n",
    "        # Freq vectors\n",
    "        # One hot\n",
    "    # BOW -  calculate the frequency of words for each document\n",
    "        # 1. set of all words found in the document se\n",
    "        # 2. Count how many times each word appears for each document\n",
    "    # TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_remove_2(x):\n",
    "\n",
    "    '''\n",
    "    diferença entre esta e a sub_remove:\n",
    "    - tirei a parte que tirava os emojis - [^0-9A-Za-z]\n",
    "    - adicionei retirar emails e html tags\n",
    "     '''\n",
    "    \n",
    "    # Remove noise\n",
    "    x = re.sub(r\"(@[A-Za-z0-9]+)|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", x, flags=re.MULTILINE)\n",
    "    \n",
    "    # Replace newline and tab characters with spaces\n",
    "    x = re.sub(r'[\\t\\n]', ' ', x)\n",
    "\n",
    "    # Remove html tags\n",
    "    x = re.sub(re.compile('<.*?>'), '', x)\n",
    "\n",
    "    # Remove email addresses\n",
    "    x = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', '', x)\n",
    "\n",
    "    # Remove isolated consonants:\n",
    "    x = re.sub(r'\\b([^aeiou])\\b',' ',x)\n",
    "\n",
    "    # Remove space before punctuation\n",
    "    x = re.sub(r'(\\s)(?!\\w)','',x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_preprocesser(data, text_column, target=None):\n",
    "\n",
    "    #### deixei as stopwords\n",
    "\n",
    "        \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # Symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # Transport & map symbols\n",
    "                           u\"\\U0001F700-\\U0001F77F\"  # Alchemical symbols\n",
    "                           u\"\\U0001F780-\\U0001F7FF\"  # Geometric shapes\n",
    "                           u\"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "                           u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "                           u\"\\U0001FA00-\\U0001FA6F\"  # Chess symbols\n",
    "                           u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "\n",
    "\n",
    "    text_data = data[text_column].copy()\n",
    "    \n",
    "    functions = [lambda x: x.lower(), \n",
    "                    expand_contractions, \n",
    "                    sub_remove_2, \n",
    "                    sub_spaces\n",
    "                ]\n",
    "\n",
    "    for function in functions:\n",
    "        text_data = text_data.apply(function)\n",
    "\n",
    "    if target is not None:\n",
    "        # tokenization\n",
    "        regexp = RegexpTokenizer(r'\\w+|' + emoji_pattern.pattern) ### adidiona emojis como tokens\n",
    "        text_data = text_data.apply(regexp.tokenize)\n",
    "           \n",
    "        words = [word for tokens in text_data for word in tokens]\n",
    "        words_unique = list(set(words))\n",
    "        words_tagged = pos_tag(words_unique)\n",
    "        words_pos_map = {word: get_wordnet_pos(pos_tag) for word, pos_tag in words_tagged}\n",
    "\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        text_data = [\n",
    "             [lemmatizer.lemmatize(word, pos=words_pos_map.get(word)) for word in sentence]\n",
    "             for sentence in text_data\n",
    "             ]\n",
    "        \n",
    "        # stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "        # additional_functions = [lemmatize_with_mapping,\n",
    "        #               lambda x: [item for item in x if item not in stopwords],\n",
    "        #               lambda x: ' '.join(x)\n",
    "        #               ]\n",
    "    \n",
    "    #     for additional_function in additional_functions:\n",
    "    #         text_data = text_data.apply(additional_function, args=(words_pos_map,) \n",
    "    #                                     if additional_function == lemmatize_with_mapping else ())\n",
    "\n",
    "    # # if target is not None:\n",
    "    #     text_data = pd.DataFrame(text_data, columns=[text_column])\n",
    "    #     text_data[target] = data[target]\n",
    "    \n",
    "    return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_preproc  = sentiment_preprocesser(train, 'lyrics', 'tag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "535805     [when, you, said, you, loved, me, did, you, me...\n",
       "7519483    [kid, naruto, rap, hook, everybody, wants, you...\n",
       "4892808    [verse, people, tell, me, i, ve, changed, i, f...\n",
       "1584150    [you, have, been, warned, about, me, do, not, ...\n",
       "7639050    [verse, i, can, see, the, end, is, coming, but...\n",
       "                                 ...                        \n",
       "1702980    [if, i, knew, when, i, was, young, that, i, be...\n",
       "4802970    [intro, lil, gotit, cash, wah, wah, wah, wah, ...\n",
       "403929     [verse, i, was, born, inside, a, home, the, yo...\n",
       "1000723    [rollin, by, the, pool, the, falling, stars, a...\n",
       "6177674    [verse, godlyrisktaker, a, yeah, epic, games, ...\n",
       "Name: lyrics, Length: 134967, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emoji_pattern = re.compile(\"[\"\n",
    "#                         u\"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "#                         u\"\\U0001F300-\\U0001F5FF\"  # Symbols & pictographs\n",
    "#                         u\"\\U0001F680-\\U0001F6FF\"  # Transport & map symbols\n",
    "#                         u\"\\U0001F700-\\U0001F77F\"  # Alchemical symbols\n",
    "#                         u\"\\U0001F780-\\U0001F7FF\"  # Geometric shapes\n",
    "#                         u\"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "#                         u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "#                         u\"\\U0001FA00-\\U0001FA6F\"  # Chess symbols\n",
    "#                         u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "#                         \"]+\", flags=re.UNICODE)\n",
    "\n",
    "# for lst in lyrics_preproc:\n",
    "#     for imj in lst:\n",
    "#         if emoji_pattern.search(imj):\n",
    "#             print(imj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag-of_words(BoW) Model\n",
    "#     create a dictionary of all the words used in the corpus\n",
    "#     convert each document to a vector that represents words available in the documents\n",
    "#     identify importance of words:\n",
    "#         Count Vector Model\n",
    "\n",
    "#         Term Frequency Vector Model\n",
    "\n",
    "#         Term Frequency-Inverse Document Frequency(TF-IDF) Model\n",
    "\n",
    "# creating count vectors for the dataset\n",
    "\n",
    "# Displaying Document Vectors\n",
    "\n",
    "# Removing Low-Frequency Words\n",
    "\n",
    "# Removing Stop Words\n",
    "\n",
    "# Distribution of words Across Different sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithms\n",
    "#     Rule-Based \n",
    "#         Based on a set of manually crafted rules\n",
    "#         can't learn or adapt beyond what they were initially programmed for\n",
    "#         can't easily change them or add new rules\n",
    "#         can't think for themselves or make decisions outside of those rules\n",
    "\n",
    "#         1. Construct explicit rules and patterns\n",
    "#         2. use lexicons - dictionary-based systems that rely on lists of words or phrases with associated sentiment scores\n",
    "#             VADER\n",
    "#             TEXTBLOB\n",
    "#             AFINN Lexicon\n",
    "#             SentiWordNet\n",
    "#             Bing Liu’s lexicon\n",
    "\n",
    "\n",
    "#     Automatic\n",
    "#         ML algorithms (SVM, NN, NB, …)\n",
    "#     Hybrid\n",
    "#         Rule-Based + Automatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### EMOJIS\n",
    "# VADER performs very well with emojis, slangs and acronyms in sentences\n",
    "\n",
    "import re\n",
    "\n",
    "# Unicode ranges for emojis\n",
    "emoji_pattern = re.compile(\"[\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FA6F\\U0001FA70-\\U0001FAFF]\", flags=re.UNICODE)\n",
    "\n",
    "for i in lyrics:\n",
    "    if emoji_pattern.search(i):\n",
    "        # print(i)\n",
    "        print(emoji_pattern.findall(i))\n",
    "        \n",
    "#####  apagar os not related com emoções e deixar os outrs???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### tag\n",
    "tag = train['tag'].copy()\n",
    "\n",
    "# functions = [lambda x: x.lower(), \n",
    "#                 expand_contractions, \n",
    "#                 sub_remove, \n",
    "#                 sub_spaces]\n",
    "\n",
    "# for function in functions:\n",
    "#     text_data = text_data.apply(function)\n",
    "\n",
    "# if target is not None:\n",
    "#     regexp = RegexpTokenizer('\\w+')\n",
    "#     text_data = text_data.apply(regexp.tokenize)\n",
    "\n",
    "#     words = [word for tokens in text_data for word in tokens]\n",
    "#     words_unique = list(set(words))\n",
    "#     words_tagged = pos_tag(words_unique)\n",
    "#     words_pos_map = {word: get_wordnet_pos(pos_tag) for word, pos_tag in words_tagged}\n",
    "\n",
    "#     # lemmatizer = WordNetLemmatizer()\n",
    "#     # text_data = [\n",
    "#     #     [lemmatizer.lemmatize(word, pos=words_pos_map.get(word)) for word in sentence]\n",
    "#     #     for sentence in text_data\n",
    "#     #     ]\n",
    "    \n",
    "#     # stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "#     additional_functions = [lemmatize_with_mapping,\n",
    "#                 #   lambda x: [item for item in x if item not in stopwords],\n",
    "#                     lambda x: ' '.join(x)\n",
    "#                     ]\n",
    "\n",
    "#     for additional_function in additional_functions:\n",
    "#         text_data = text_data.apply(additional_function, args=(words_pos_map,) \n",
    "#                                     if additional_function == lemmatize_with_mapping else ())\n",
    "\n",
    "# # if target is not None:\n",
    "#     text_data = pd.DataFrame(text_data, columns=[text_column])\n",
    "#     text_data[target] = data[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lyrics_train = pd.read_csv(r'C:\\Users\\bruna\\Desktop\\data_updated\\lyrics_train.csv', index_col=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplest task -> positive or negative\n",
    "# More complex -> rank the attitude of this text from 1 to 5\n",
    "# Advanced -> detect the target, source, or complex attitude type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### VADER\n",
    "# {'compound': 0.6588, 'neg': 0.0, 'neu': 0.406, 'pos': 0.594}\n",
    "# [-1] (Extremely Negative)\n",
    "# [1] (Extremely Positive)\n",
    "# [0] Neutral or Neither"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEXTBLOB\n",
    "# `Sentiment(polarity=1.0, subjectivity=0.75)`\n",
    "\n",
    "# polarity → measures the sentiment or emotional tone of the text\n",
    "\n",
    "# - ranges between [-1, 1]\n",
    "#     - 1 indicates a highly negative sentiment\n",
    "#     - 0 indicates a neutral sentiment\n",
    "#     - 1 indicates a highly positive sentiment\n",
    "    \n",
    "\n",
    "# subjectivity → measures how objective or subjective the text is\n",
    "\n",
    "# - ranges between [0, 1]\n",
    "#     - 0 indicates a highly objective piece of text → fact-based content\n",
    "#     - 1 indicates a highly subjective (opinionated) piece of text → personal opinions, emotions, judgements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenges:\n",
    "#     phrase with negation\n",
    "#     negation, inverted word order - Disliking horror movies is not uncommon\n",
    "#     The adverb sometimes modifies the sentiment - ex: Somentimes\n",
    "#     sarcasm\n",
    "#     negative term used in a positive way\n",
    "#     difficult to categorize\n",
    "\n",
    "#     Objective / Subjective\n",
    "#     Context and Polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context-Dependent Erros:\n",
    "#     Sarcasm\n",
    "#     Polarity\n",
    "#     Polysemy\n",
    "#     Emojis -  emojis sometimes cannot be classified accurately and thus are removed from many analysis\n",
    "#         (If those are removed from text, one ends up with a noncomprehensive analysis)\n",
    "#     gender stereotypes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tm_proj_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
